{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Qassida.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Qassida : un générateur de poésie arabe avec LSTM sous Pytorch\n",
        "\n",
        "\n",
        "*   A rédiger : Membres de l'équipe\n",
        "*   Introduction + problématique \n",
        "*   Etapes de la réalistion\n",
        "\n"
      ],
      "metadata": {
        "id": "2zn4yMbbTFMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import des librairies :     \n",
        "Nous commençons par l'import des librairies dont nous aurons besoin pour pouvoir implémenter notre solution\n",
        "> * NumPy pour la gestion des calculs matriciels et vectoriels\n",
        "> * PyTorch permet d'effectuer les calculs tensoriels nécessaires notamment pour l'apprentissage profond\n",
        "> * Beautiful Soup pour le web scraping et la génération du dataset  "
      ],
      "metadata": {
        "id": "TkNPr3NnTx2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as func\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "bBkbe9RYGtn8"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chargement des données\n",
        "Initialement nous exécutons un programme de web scraping qui fournit les données sous forme d'un fichier texte, pour effectuer l'entrainement après.\n",
        "\n",
        "> Nous chargeons d'abord, le résultat du scraping à partir du fichier texte pour le pré-traiter "
      ],
      "metadata": {
        "id": "Ei-bJa8dHABh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ouvrir le fichier texte lire les données sous forme de 'texte'\n",
        "\n",
        "with open('poems_of_Darwish.txt', 'r', encoding=\"utf-8\") as f:\n",
        "  poem = f.read();"
      ],
      "metadata": {
        "id": "eJI4gzVmIkyy"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Visualisons les 50 premiers caractères du texte :"
      ],
      "metadata": {
        "id": "kK3e5FMKJ21b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poem[:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tdTIH7BdJ9WB",
        "outputId": "f374e7a0-86d9-43f0-f6d8-00439acad1b5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'علي شاطء البحر بنت  وللبنت اهل\\nوللاهل بيت  وللبيت '"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorisation\n",
        "Dans ce qui suit, nous utilisons les structures 'dictionaries' de python pour convertir les caractères en un entier unique"
      ],
      "metadata": {
        "id": "GY1XQu7FLyGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction 1 : char_to_int \n",
        "# Fonction 2 : int_to_char \n",
        "\n",
        "chars = tuple(set(poem))\n",
        "\n",
        "int_to_char = dict(enumerate(chars))\n",
        "char_to_int = {char: ii for ii, char in int_to_char.items()}\n",
        "\n",
        "encoded = np.array([char_to_int[char] for char in poem])"
      ],
      "metadata": {
        "id": "ad3cT7kHLtjU"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Visualisons l'encodage des 50 premiers caractères"
      ],
      "metadata": {
        "id": "1Y_pYyRbNp-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded[:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecUx5Y0HNy-3",
        "outputId": "fd8c95d8-64be-4296-e555-5b58215d12a4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([57, 59, 14, 55, 51, 36, 50,  4, 55, 36, 59, 38,  9, 13, 55, 38, 30,\n",
              "       39, 55, 55, 62, 59, 59, 38, 30, 39, 55, 36, 19, 59, 42, 62, 59, 59,\n",
              "       36, 19, 59, 55, 38, 14, 39, 55, 55, 62, 59, 59, 38, 14, 39, 55])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Partie pré-traitement des données\n",
        "\n",
        "Dans le modèle charRNN que nous voulant utiliser, le LSTM prend en entrée des données one-hot-encoded \n",
        "i.e un vecteur dont la taille est celle du vocabulaire et pour chaque caractère un '1' est placé à\n",
        "la position du caractère dans ce vecteur, sinon '0'"
      ],
      "metadata": {
        "id": "_aM8wwlTQGDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(vect, taille_vocab):\n",
        "  one_hot = np.zeros((vect.size, taille_vocab), dtype=np.float32)\n",
        "    \n",
        "    # Fill the appropriate elements with ones\n",
        "  one_hot[np.arange(one_hot.shape[0]), vect.flatten()] = 1.\n",
        "    \n",
        "    # Finally reshape it to get back to the original array\n",
        "  one_hot = one_hot.reshape((*vect.shape, taille_vocab))\n",
        "    \n",
        "  return one_hot"
      ],
      "metadata": {
        "id": "7vPwg8mjN2Av"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Division en mini-batches d'entrainement\n",
        "\n",
        "> On divise le vecteur des caractères encodés en séquence de taile seq_length selon le batch_size.\n"
      ],
      "metadata": {
        "id": "anqZrtAoQluw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Créatio des batches\n",
        "> 1 - D'abord, il faut retrancher certain caractères pour avoir des batches de taille complète uniquement.\n",
        "> 2 - Diviser le vecteur de caractères en N batches.\n",
        "> 3 - Parcourir le vecteur qui est maintenant divisé en N sous-vecteurs pour avoir les mini-batches. "
      ],
      "metadata": {
        "id": "0jZG5sUgQPIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrainer et tester les Batched\n",
        "> 1 - Créer 2 batches x,y où : x est le input batch et y est le training batch qui est exactement x mais décalé d'un seul caractère."
      ],
      "metadata": {
        "id": "GDWlelXnRuvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batches(arr, batch_size, seq_length):\n",
        "\n",
        "    batch_size_total = batch_size * seq_length\n",
        "\n",
        "    # Nombre total de batches que nous pouvons avoir\n",
        "    n_batches = len(arr)//batch_size_total\n",
        "    \n",
        "    # Garder que les batches complets \n",
        "    arr = arr[:n_batches * batch_size_total]\n",
        "\n",
        "    # Reshape en lignes de batch_size \n",
        "    arr = arr.reshape((batch_size, -1))\n",
        "    \n",
        "    # Itérer sur chaque séquence de caractères\n",
        "    for n in range(0, arr.shape[1], seq_length):\n",
        "\n",
        "        x = arr[:, n:n+seq_length]\n",
        "        \n",
        "        y = np.zeros_like(x)\n",
        "        try:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
        "        except IndexError:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
        "        yield x, y"
      ],
      "metadata": {
        "id": "sh9y2OhSSByl"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualiser la sortie \n",
        "> Visualisons ce que les batches sur 100 caractères de données encodées donne :"
      ],
      "metadata": {
        "id": "-4KCO0DoTAg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batches = get_batches(encoded, 8, 50)\n",
        "x, y = next(batches)\n",
        "\n",
        "# Les 10 premiers éléments d'une séquence\n",
        "print('x\\n', x[:10, :10])\n",
        "print('\\ny\\n', y[:10, :10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdynGBa2Slw_",
        "outputId": "874d59b5-de23-4435-84bb-063a4b8a05c6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x\n",
            " [[57 59 14 55 51 36 50  4 55 36]\n",
            " [36 55 36 59  1 36 19 13 14 30]\n",
            " [23 55 36 59 62 28 39 55 12 14]\n",
            " [42 62  1 13 30 36 55 36 59 14]\n",
            " [55 48 30 55 36 59 13 62  9 55]\n",
            " [62 55 59 63 19 42 36 59 48 55]\n",
            " [36 55 48 36  4 19 36 55 14 13]\n",
            " [30 62 36 57 55 36 59  9 43 36]]\n",
            "\n",
            "y\n",
            " [[59 14 55 51 36 50  4 55 36 59]\n",
            " [55 36 59  1 36 19 13 14 30 55]\n",
            " [55 36 59 62 28 39 55 12 14 55]\n",
            " [62  1 13 30 36 55 36 59 14 55]\n",
            " [48 30 55 36 59 13 62  9 55 62]\n",
            " [55 59 63 19 42 36 59 48 55 39]\n",
            " [55 48 36  4 19 36 55 14 13 62]\n",
            " [62 36 57 55 36 59  9 43 36 13]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Définir le modèle avec PyTorch\n",
        "> On commence d'abord par définir les couches (layers) du modèle ensuite les fonctions (opérations), après on doit aussi écrire le code pour les opérations : forward (passer un caractère)\n",
        "\n",
        "\n",
        "> __Remarque__ : on essaye d'utiliser les GPUs disponibles sinon, sélectionner le CPU"
      ],
      "metadata": {
        "id": "bpuwSRq3cg5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check if GPU is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if(train_on_gpu):\n",
        "    print('L\\'entrainement se fera sur GPU')\n",
        "else: \n",
        "    print('Aucun GPU trouvé ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8jbTDrzbM4L",
        "outputId": "a08c487b-16f3-415e-f8b3-3a78ffd1c7fb"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aucun GPU trouvé \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CharRNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
        "                               drop_prob=0.5, lr=0.001):\n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden = n_hidden\n",
        "        self.lr = lr\n",
        "        \n",
        "        # Dictionnaires des caractères \n",
        "        self.chars = tokens\n",
        "        self.int_to_char = dict(enumerate(self.chars))\n",
        "        self.char_to_int = {ch: ii for ii, ch in self.int_to_char.items()}\n",
        "        \n",
        "        ## Définir le LSTM \n",
        "        self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        ## Définir la couche de dropout\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        \n",
        "        ## Définir la couche de sortie\n",
        "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
        "      \n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "                \n",
        "        ## Recevoir la sortie et le nouvel état 'hidden' depuis le LSTM\n",
        "        r_output, hidden = self.lstm(x, hidden)\n",
        "        \n",
        "        ## Passer par une couche de dropout\n",
        "        out = self.dropout(r_output)\n",
        "        \n",
        "        # Empiler (stacking) les sorties des LSTM \n",
        "        # Ici contiguous() c'est pour faire le reshape du vecteur \n",
        "        out = out.contiguous().view(-1, self.n_hidden)\n",
        "        \n",
        "        ## Faire passer x dans la couche entièrement connecté\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        # Retourner la sortie finale et le hidden state final\n",
        "        return out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initialiser le hidden state '''\n",
        "        # Créations de 2 tensors de dimensions n_layers x batch_size x n_hidden,\n",
        "        # initialiser à 0 pour le hidden state et cell state (cellule état) du LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "metadata": {
        "id": "ZEzg97bIdR5F"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, data, epochs=5, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
        "    ''' Entrainer le modèle\n",
        "    \n",
        "        Arguments\n",
        "        ---------\n",
        "        \n",
        "        net: Le réseau charRNN\n",
        "        data: Texte du dataset \n",
        "        epochs: Nombre d'epochs pour entrainer \n",
        "        batch_size: Nombre de mini-séquences par mini-batch (taille du batch)\n",
        "\n",
        "        seq_length: Nombre de caractères par mini-batch\n",
        "        lr: learning rate (taux d'apprentissage)\n",
        "        clip: gradient clipping\n",
        "        val_frac: Fraction de données à garder pour l'étape de validation\n",
        "        print_every: Nombre d'étapes à compter jusqu'au prochain affichage du loss\n",
        "    \n",
        "    '''\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    valid_loss_min = np.Inf \n",
        "\n",
        "\n",
        "    net.train()\n",
        "    \n",
        "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # Création des données de less et de validation\n",
        "    val_idx = int(len(data)*(1-val_frac))\n",
        "    data, val_data = data[:val_idx], data[val_idx:]\n",
        "    \n",
        "    if(train_on_gpu):\n",
        "        net.cuda()\n",
        "    \n",
        "    counter = 0\n",
        "    n_chars = len(net.chars)\n",
        "    for e in range(epochs):\n",
        "        # initialiser l'état hidden \n",
        "        h = net.init_hidden(batch_size)\n",
        "        \n",
        "        for x, y in get_batches(data, batch_size, seq_length):\n",
        "            counter += 1\n",
        "            \n",
        "            x = one_hot(x, n_chars)\n",
        "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
        "            \n",
        "            if(train_on_gpu):\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "            h = tuple([each.data for each in h])\n",
        "\n",
        "            # initialiser les gradients cumulés \n",
        "            net.zero_grad()\n",
        "            \n",
        "            # Recevoir la sortie \n",
        "            output, h = net(inputs, h)\n",
        "            \n",
        "            # Calculer la perte (loss) et effectuer une backpropagation\n",
        "            loss = train_loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
        "            loss.backward()\n",
        "            # `clip_grad_norm` permet de controler l'explosion du gradient dans RNNs / LSTMs.\n",
        "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "            opt.step()\n",
        "            \n",
        "            # statistiques du loss\n",
        "            if counter % print_every == 0:\n",
        "                \n",
        "                val_h = net.init_hidden(batch_size)\n",
        "                val_losses = []\n",
        "                net.eval()\n",
        "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
        "                    \n",
        "                    x = one_hot(x, n_chars)\n",
        "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
        "                    \n",
        "                    \n",
        "                    val_h = tuple([each.data for each in val_h])\n",
        "                    \n",
        "                    inputs, targets = x, y\n",
        "                    if(train_on_gpu):\n",
        "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "                    output, val_h = net(inputs, val_h)\n",
        "                    val_loss = valid_loss =  criterion(output, targets.view(batch_size*seq_length).long())\n",
        "                \n",
        "                    val_losses.append(val_loss.item())\n",
        "                \n",
        "                net.train() # Remettre en état d'entrainement après la phase de validation\n",
        "                \n",
        "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                      \"Etape: {}...\".format(counter),\n",
        "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
        "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
        "                \n",
        "    # Sauvegarder le modèle si la valeur de loss (perte) diminue\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('validation loss a diminué({:.6f} --> {:.6f}).  Sauvegarde du modèle ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        model_name = 'Darwish_model.net'\n",
        "\n",
        "        checkpoint = {'n_hidden': net.n_hidden,\n",
        "                       'n_layers': net.n_layers,\n",
        "                       'state_dict': net.state_dict(),\n",
        "                       'tokens': net.chars}\n",
        "\n",
        "        with open(model_name, 'wb') as f:\n",
        "            torch.save(model_name, f)"
      ],
      "metadata": {
        "id": "fhO6CTPVergM"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrainement\n",
        "> __Remarque :__ L'entrainement sur Google Colab avec 50 epoch prend 4 heurs."
      ],
      "metadata": {
        "id": "N7InzVHSjkNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Définir le network (réseau)\n",
        "n_hidden=512\n",
        "n_layers=5\n",
        "\n",
        "net = CharRNN(chars, n_hidden, n_layers)\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMixFNI2jieh",
        "outputId": "aa16913c-50dc-4140-b65b-2f1a8cf6bc80"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CharRNN(\n",
            "  (lstm): LSTM(67, 512, num_layers=5, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=67, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "seq_length = 100\n",
        "n_epochs = 1\n",
        "\n",
        "# Entrainer le modèle \n",
        "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coiKo_wNj9Gd",
        "outputId": "56cdb9cf-830c-4667-ae0d-57f9d8b59e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/1... Etape: 10... Loss: 2.9922... Val Loss: 2.9651\n",
            "Epoch: 1/1... Etape: 20... Loss: 2.9748... Val Loss: 2.9587\n",
            "Epoch: 1/1... Etape: 30... Loss: 2.9592... Val Loss: 2.9568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Darwish_model.net', 'rb') as f:\n",
        "    if train_on_gpu:\n",
        "            checkpoint = torch.load(f)\n",
        "    else:        \n",
        "        checkpoint = torch.load(f,map_location=torch.device('cpu'))\n",
        "\n",
        "    \n",
        "loaded = CharRNN(checkpoint['tokens'], n_hidden=checkpoint['n_hidden'], n_layers=checkpoint['n_layers'])\n",
        "loaded.load_state_dict(checkpoint['state_dict'])"
      ],
      "metadata": {
        "id": "imUVR2uqkEk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(net, char, h=None, top_k=None):\n",
        "        \n",
        "        x = np.array([[net.char_to_int[char]]])\n",
        "        x = one_hot(x, len(net.chars))\n",
        "        inputs = torch.from_numpy(x)\n",
        "        \n",
        "        if(train_on_gpu):\n",
        "            inputs = inputs.cuda()\n",
        "        \n",
        "        h = tuple([each.data for each in h])\n",
        "        \n",
        "        out, h = net(inputs, h)\n",
        "\n",
        "        # Calculer les probabilités du prochain caractère\n",
        "        p = F.softmax(out, dim=1).data\n",
        "        if(train_on_gpu):\n",
        "            p = p.cpu() # passer au cpu\n",
        "        \n",
        "        # Garder les caractères avec les plus grandes probabiités\n",
        "        if top_k is None:\n",
        "            top_ch = np.arange(len(net.chars))\n",
        "        else:\n",
        "            p, top_ch = p.topk(top_k)\n",
        "            top_ch = top_ch.numpy().squeeze()\n",
        "        \n",
        "        # Choisir le prochain caractère à l'aide d'une fonction aléatoire\n",
        "        p = p.numpy().squeeze()\n",
        "        char = np.random.choice(top_ch, p=p/p.sum())\n",
        "        \n",
        "        # Retourner le code du caractère et le convertir en caractère  \n",
        "        return net.int_to_char[char], h"
      ],
      "metadata": {
        "id": "kdVm8Fhlkyup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(net, size, prime='The', top_k=None):\n",
        "        \n",
        "    if(train_on_gpu):\n",
        "        net.cuda()\n",
        "    else:\n",
        "        net.cpu()\n",
        "    \n",
        "    net.eval() # mode d'évaluation\n",
        "    \n",
        "    # D'abord, traiter le premier \n",
        "    chars = [ch for ch in prime]\n",
        "    h = net.init_hidden(1)\n",
        "    for ch in prime:\n",
        "        char, h = predict(net, ch, h, top_k=top_k)\n",
        "\n",
        "    chars.append(char)\n",
        "    \n",
        "    # Passer le caractère précédent pour avoir le prochaine\n",
        "    for ii in range(size):\n",
        "        char, h = predict(net, chars[-1], h, top_k=top_k)\n",
        "        chars.append(char)\n",
        "\n",
        "    return ''.join(chars)"
      ],
      "metadata": {
        "id": "bJVIpSpPk1wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample(loaded, 300, prime='السيف', top_k=5))"
      ],
      "metadata": {
        "id": "JlRfZ4Xfk3l6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}