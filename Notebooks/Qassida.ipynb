{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Qassida.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Qassida : un générateur de poésie arabe avec LSTM sous Pytorch\n",
        "\n",
        "\n",
        "*   A rédiger : Membres de l'équipe\n",
        "*   Introduction + problématique \n",
        "*   Etapes de la réalistion\n",
        "\n"
      ],
      "metadata": {
        "id": "2zn4yMbbTFMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import des librairies :     \n",
        "Nous commençons par l'import des librairies dont nous aurons besoin pour pouvoir implémenter notre solution\n",
        "> * NumPy pour la gestion des calculs matriciels et vectoriels\n",
        "> * PyTorch permet d'effectuer les calculs tensoriels nécessaires notamment pour l'apprentissage profond\n",
        "> * Beautiful Soup pour le web scraping et la génération du dataset  "
      ],
      "metadata": {
        "id": "TkNPr3NnTx2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as func\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "bBkbe9RYGtn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chargement des données\n",
        "Initialement nous exécutons un programme de web scraping qui fournit les données sous forme d'un fichier texte, pour effectuer l'entrainement après.\n",
        "\n",
        "> Nous chargeons d'abord, le résultat du scraping à partir du fichier texte pour le pré-traiter "
      ],
      "metadata": {
        "id": "Ei-bJa8dHABh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ouvrir le fichier texte lire les données sous forme de 'texte'\n",
        "\n",
        "with open('poems_of_Darwish.txt', 'r', encoding=\"utf-8\") as f:\n",
        "  poem = f.read();"
      ],
      "metadata": {
        "id": "eJI4gzVmIkyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Visualisons les 50 premiers caractères du texte :"
      ],
      "metadata": {
        "id": "kK3e5FMKJ21b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poem[:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tdTIH7BdJ9WB",
        "outputId": "eb423dbb-811c-4127-a11f-68d8592dd273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'علي شاطء البحر بنت  وللبنت اهل\\nوللاهل بيت  وللبيت '"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorisation\n",
        "Dans ce qui suit, nous utilisons les structures 'dictionaries' de python pour convertir les caractères en un entier unique"
      ],
      "metadata": {
        "id": "GY1XQu7FLyGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction 1 : char_to_int \n",
        "# Fonction 2 : int_to_char \n",
        "\n",
        "vocab = tuple(set(poem))\n",
        "\n",
        "int_to_char = dict(enumerate(vocab))\n",
        "char_to_int = {char: ii for ii, char in int_to_char.items()}\n",
        "\n",
        "encoded = np.array([char_to_int[char] for char in poem])"
      ],
      "metadata": {
        "id": "ad3cT7kHLtjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Visualisons l'encodage des 50 premiers caractères"
      ],
      "metadata": {
        "id": "1Y_pYyRbNp-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded[:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecUx5Y0HNy-3",
        "outputId": "194ca512-f004-4a71-a140-4fbad039c340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([46, 55, 45, 42, 26, 53, 66, 47, 42, 53, 55, 14,  3,  4, 42, 14, 54,\n",
              "       16, 42, 42, 49, 55, 55, 14, 54, 16, 42, 53,  6, 55, 17, 49, 55, 55,\n",
              "       53,  6, 55, 42, 14, 45, 16, 42, 42, 49, 55, 55, 14, 45, 16, 42])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Partie pré-traitement des données\n",
        "\n",
        "Dans le modèle charRNN que nous voulant utiliser, le LSTM prend en entrée des données one-hot-encoded \n",
        "i.e un vecteur dont la taille est celle du vocabulaire et pour chaque caractère un '1' est placé à\n",
        "la position du caractère dans ce vecteur, sinon '0'"
      ],
      "metadata": {
        "id": "_aM8wwlTQGDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(vect, taille_vocab):\n",
        "  one_hot = np.zeros((arr.size, n_labels), dtype=np.float32)\n",
        "    \n",
        "    # Fill the appropriate elements with ones\n",
        "  one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
        "    \n",
        "    # Finally reshape it to get back to the original array\n",
        "  one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
        "    \n",
        "  return one_hot"
      ],
      "metadata": {
        "id": "7vPwg8mjN2Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Division en mini-batches d'entrainement\n",
        "\n",
        "> On divise le vecteur des caractères encodés en séquence de taile seq_length selon le batch_size.\n"
      ],
      "metadata": {
        "id": "anqZrtAoQluw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Créatio des batches\n",
        "> 1 - D'abord, il faut retrancher certain caractères pour avoir des batches de taille complète uniquement.\n",
        "> 2 - Diviser le vecteur de caractères en N batches.\n",
        "> 3 - Parcourir le vecteur qui est maintenant divisé en N sous-vecteurs pour avoir les mini-batches. "
      ],
      "metadata": {
        "id": "0jZG5sUgQPIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrainer et tester les Batched\n",
        "> 1 - Créer 2 batches x,y où : x est le input batch et y est le training batch qui est exactement x mais décalé d'un seul caractère."
      ],
      "metadata": {
        "id": "GDWlelXnRuvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batches(arr, batch_size, seq_length):\n",
        "\n",
        "    batch_size_total = batch_size * seq_length\n",
        "\n",
        "    # Nombre total de batches que nous pouvons avoir\n",
        "    n_batches = len(arr)//batch_size_total\n",
        "    \n",
        "    # Garder que les batches complets \n",
        "    arr = arr[:n_batches * batch_size_total]\n",
        "\n",
        "    # Reshape en lignes de batch_size \n",
        "    arr = arr.reshape((batch_size, -1))\n",
        "    \n",
        "    # Itérer sur chaque séquence de caractères\n",
        "    for n in range(0, arr.shape[1], seq_length):\n",
        "\n",
        "        x = arr[:, n:n+seq_length]\n",
        "        \n",
        "        y = np.zeros_like(x)\n",
        "        try:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
        "        except IndexError:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
        "        yield x, y"
      ],
      "metadata": {
        "id": "sh9y2OhSSByl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualiser la sortie \n",
        "> Visualisons ce que les batches sur 100 caractères de données encodées donne :"
      ],
      "metadata": {
        "id": "-4KCO0DoTAg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batches = get_batches(encoded, 8, 50)\n",
        "x, y = next(batches)\n",
        "\n",
        "# Les 10 premiers éléments d'une séquence\n",
        "print('x\\n', x[:10, :10])\n",
        "print('\\ny\\n', y[:10, :10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdynGBa2Slw_",
        "outputId": "ff4948d9-108f-4b77-8e84-778aecc498b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x\n",
            " [[46 55 45 42 26 53 66 47 42 53]\n",
            " [53 42 53 55 30 53  6  4 45 54]\n",
            " [35 42 53 55 49 27 16 42 60 45]\n",
            " [17 49 30  4 54 53 42 53 55 45]\n",
            " [42  1 54 42 53 55  4 49  3 42]\n",
            " [49 42 55 22  6 17 53 55  1 42]\n",
            " [53 42  1 53 47  6 53 42 45  4]\n",
            " [54 49 53 46 42 53 55  3 18 53]]\n",
            "\n",
            "y\n",
            " [[55 45 42 26 53 66 47 42 53 55]\n",
            " [42 53 55 30 53  6  4 45 54 42]\n",
            " [42 53 55 49 27 16 42 60 45 42]\n",
            " [49 30  4 54 53 42 53 55 45 42]\n",
            " [ 1 54 42 53 55  4 49  3 42 49]\n",
            " [42 55 22  6 17 53 55  1 42 16]\n",
            " [42  1 53 47  6 53 42 45  4 49]\n",
            " [49 53 46 42 53 55  3 18 53  4]]\n"
          ]
        }
      ]
    }
  ]
}